{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b2db8b",
   "metadata": {},
   "source": [
    "\n",
    "# Datasets+Villarruel.ipynb\n",
    "\n",
    "**Preentrega – Data Science 1 (Coderhouse, Argentina)**  \n",
    "Autor: *Tobias Villarruel*  \n",
    "Fecha: (completar)\n",
    "\n",
    "## Consigna\n",
    "- Identificar **3 datasets** con **≥ 2000 filas** y **≥ 15 columnas** (Kaggle, GitHub, Google Dataset Search o propio).\n",
    "- Subirlos a **GitHub**.\n",
    "- **Cargar los archivos con Pandas** y **describir variables potencialmente interesantes** en cada caso.\n",
    "- Entregar un archivo **.ipynb** con el nombre: `Datasets+Apellido.ipynb`.\n",
    "\n",
    "> **Nota**: Este notebook carga y explora 3 datasets confirmados por el alumno:  \n",
    "> 1) World Development Indicators (World Bank)  \n",
    "> 2) NYC Yellow Taxi Trip Data (TLC)  \n",
    "> 3) Global Development Indicators 2000–2020 (Kaggle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced1fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RAW_DIR = Path(\"data/raw\")\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def quick_report(df: pd.DataFrame, sample=5):\n",
    "    \"\"\"Pequeño reporte para verificar requisitos y mostrar estructura.\"\"\"\n",
    "    print(\"Shape (filas, columnas):\", df.shape)\n",
    "    display(df.head(sample))\n",
    "    print(\"\\nTipos de datos:\")\n",
    "    display(df.dtypes.value_counts())\n",
    "    na_pct = df.isna().mean().sort_values(ascending=False)\n",
    "    print(\"\\n% de NA por columna (top 10):\")\n",
    "    display(na_pct.head(10))\n",
    "    print(\"\\nResumen numérico:\")\n",
    "    display(df.describe(include=[np.number]).T.head(10))\n",
    "    print(\"\\nResumen categórico:\")\n",
    "    display(df.describe(include=[object]).T.head(10))\n",
    "\n",
    "def assert_requisitos(df: pd.DataFrame, min_rows=2000, min_cols=15):\n",
    "    assert df.shape[0] >= min_rows, f\"El dataset tiene {df.shape[0]} filas (< {min_rows}).\"\n",
    "    assert df.shape[1] >= min_cols, f\"El dataset tiene {df.shape[1]} columnas (< {min_cols}).\"\n",
    "    print(f\"✅ Cumple requisitos: filas ≥ {min_rows} y columnas ≥ {min_cols}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c1984",
   "metadata": {},
   "source": [
    "\n",
    "## 1) World Development Indicators (WDI) — World Bank\n",
    "\n",
    "**Fuente (info y descarga):**\n",
    "- World Bank Open Data / WDI (descripción general).  \n",
    "- DataBank WDI (permite descargar CSV).\n",
    "\n",
    "**Instrucciones de descarga rápida (una vez):**\n",
    "1. Ingresar a **DataBank WDI** y exportar como **CSV** (opción *Download*).  \n",
    "2. Descomprimir `WDI_csv.zip` y copiar **`WDIData.csv`** en `data/raw/` de este repo.\n",
    "\n",
    "> Alternativa: si ya tenés un CSV espejo (por ejemplo de un repo público), colocarlo en `data/raw/WDIData.csv` con el mismo nombre.\n",
    "\n",
    "**Campos típicos:** `Country Name`, `Country Code`, `Indicator Name`, `Indicator Code`, `1960`, `1961`, … (columnas por año).  \n",
    "Esto garantiza **≫ 15 columnas** y **≫ 2000 filas**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbf99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta local esperada (colocar el archivo antes de ejecutar esta celda)\n",
    "wdi_path = RAW_DIR / \"WDIData.csv\"\n",
    "\n",
    "# Carga segura (solo primeras columnas para visualización rápida si es muy ancho)\n",
    "wdi = pd.read_csv(wdi_path)\n",
    "quick_report(wdi)\n",
    "assert_requisitos(wdi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b79425",
   "metadata": {},
   "source": [
    "\n",
    "**Variables potencialmente interesantes (ejemplos):**\n",
    "- **PIB per cápita (current US$)**: aproximación del nivel de desarrollo económico.  \n",
    "- **Esperanza de vida al nacer**: salud y bienestar general.  \n",
    "- **Mortalidad infantil (por cada 1.000 nacidos vivos)**: calidad de sistemas sanitarios.  \n",
    "- **Tasa de desempleo**: condiciones del mercado laboral.  \n",
    "- **Gasto en educación / salud (% del PIB)**: inversión social.  \n",
    "\n",
    "**Usos posibles:** análisis comparativo entre países, series temporales por país, correlaciones (p.ej., PIB per cápita vs. esperanza de vida), clustering por perfiles de desarrollo, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab389c15",
   "metadata": {},
   "source": [
    "\n",
    "## 2) NYC Yellow Taxi Trip Data — NYC TLC\n",
    "\n",
    "**Fuente (info y descarga):**\n",
    "- Página oficial TLC Trip Record Data (con enlaces a CSV por mes/año).\n",
    "- También listado en NYC Open Data y en Azure Open Datasets.\n",
    "\n",
    "**Instrucciones de uso en este notebook:**  \n",
    "- Por conveniencia, este ejemplo apunta al CSV **enero 2019**.  \n",
    "- Si el CSV es muy grande, se puede limitar a `nrows` para exploración rápida (aun así se cumplen las ≥ 2000 filas).\n",
    "\n",
    "> **Nota**: Si el enlace remoto da error de red/permisos, descargá el archivo **`yellow_tripdata_2019-01.csv`** y colocalo en `data/raw/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af263eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Opción A: lectura directa desde URL (puede tardar / fallar si no hay internet)\n",
    "# url_taxi = \"https://nyc-tlc.s3.amazonaws.com/trip+data/yellow_tripdata_2019-01.csv\"\n",
    "# taxi = pd.read_csv(url_taxi, nrows=200_000)\n",
    "\n",
    "# Opción B: archivo local previamente descargado\n",
    "taxi_path = RAW_DIR / \"yellow_tripdata_2019-01.csv\"\n",
    "taxi = pd.read_csv(taxi_path, nrows=200_000)  # nrows para exploración inicial\n",
    "quick_report(taxi)\n",
    "assert_requisitos(taxi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c22b7",
   "metadata": {},
   "source": [
    "\n",
    "**Variables potencialmente interesantes (ejemplos):**\n",
    "- **tpep_pickup_datetime / tpep_dropoff_datetime**: permiten derivar **duración** del viaje.  \n",
    "- **trip_distance**: distancia recorrida.  \n",
    "- **fare_amount, total_amount, tip_amount, tolls_amount**: estructura de la tarifa.  \n",
    "- **passenger_count**: demanda por viaje.  \n",
    "- **PULocationID / DOLocationID**: zonas de origen/destino (análisis espacial).  \n",
    "- **payment_type**: efectivo/tarjeta (relación con propinas).  \n",
    "\n",
    "**Usos posibles:** patrones temporales (hora/día), relación distancia–precio–propina, mapas/zonas con mayor demanda, outliers (viajes anómalos), etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401cc7c",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Global Development Indicators 2000–2020 — Kaggle\n",
    "\n",
    "**Fuente (Kaggle):** *Global Development Indicators 2000–2020* (compilación de indicadores económicos, sociales y ambientales).\n",
    "\n",
    "**Descarga con Kaggle API (opcional):**\n",
    "```bash\n",
    "# Requiere tener configuradas tus credenciales de Kaggle (~/.kaggle/kaggle.json)\n",
    "pip install kaggle\n",
    "kaggle datasets download -d michaelmatta0/global-development-indicators-2000-2020 -p data/raw\n",
    "unzip data/raw/global-development-indicators-2000-2020.zip -d data/raw/\n",
    "```\n",
    "> Luego, asegurate de tener el CSV principal (por ejemplo `Global_Development_2000_2020.csv`) en `data/raw/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ajustar el nombre del archivo según el CSV incluido en el zip\n",
    "gdi_path = RAW_DIR / \"Global_Development_2000_2020.csv\"  # renombrar si difiere\n",
    "gdi = pd.read_csv(gdi_path)\n",
    "quick_report(gdi)\n",
    "assert_requisitos(gdi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f267410",
   "metadata": {},
   "source": [
    "\n",
    "**Variables potencialmente interesantes (ejemplos):**\n",
    "- **Indicadores económicos**: PIB, PIB per cápita, inflación, comercio exterior.  \n",
    "- **Indicadores sociales**: esperanza de vida, mortalidad infantil, acceso a educación.  \n",
    "- **Indicadores ambientales**: emisiones de CO₂ per cápita, energías renovables (%), calidad del aire.  \n",
    "- **Tecnología**: usuarios de internet, suscripciones móviles, I+D (% del PIB).  \n",
    "\n",
    "**Usos posibles:** análisis 2000–2020 por país/región, evolución temporal de indicadores clave, correlaciones entre desarrollo humano y crecimiento, comparación con WDI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0e6a6",
   "metadata": {},
   "source": [
    "\n",
    "## ✅ Checklist de la consigna\n",
    "- [x] **3 datasets** seleccionados, con enlaces oficiales a sus fuentes.\n",
    "- [x] Cada dataset cumple **≥ 2000 filas** y **≥ 15 columnas** (ver celdas de `assert_requisitos`).\n",
    "- [x] **Carga con Pandas** y EDA breve (shape, tipos, NA, descripciones).\n",
    "- [x] **Descripción de variables** potencialmente interesantes y contexto.\n",
    "- [x] Listo para **hostear en GitHub** (sugerencia: agregar `data/raw/` al repo, o bien scripts de descarga).\n",
    "\n",
    "### Sugerencias extra\n",
    "- Si los archivos son muy pesados, subir **muestras** (e.g., 50–100 MB) a GitHub y mantener los originales fuera del repo (usar *Releases* o almacenamiento externo).  \n",
    "- Probar el notebook cambiando rutas/archivos (`data/raw/...`) para verificar robustez con **distintas entradas**.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
